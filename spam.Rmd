---
title: KNN - SVM
subtitle: Ejercicio Obligatorio
author:
- name: William Chavarría
  affiliation: Máxima Formación
  email: wchavarria@tigo.com.gt
date: '`r format(Sys.Date())`'
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    highlight: pygments
    theme: spacelab
    css: custom_knn.css
    fig_caption: true
    df_print: paged
bibliography: [paquetes_knn.bib, knn.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo        = TRUE, 
                      include     = TRUE,
                      cache       = FALSE,
                      fig.align   = 'center',
                      message     = FALSE,
                      warning     = FALSE, 
                      comment     = NA, 
                      highlight   = TRUE,
                      strip.white = TRUE,
                      dev         = "svglite",
                      fig.width   = 8,
                      fig.asp     = 0.618,
                      fig.show    = "hold",
                      fig.align   = "center")
```

# spam {.tabset .tabset-fade .tabset-pills}

## Descripción

Datos spam. Se desea realizar un modelo para clasificar si un correo se puede
considerar spam o no. Se nos proporciona un conjunto de datos con 4.601
observaciones y 58 variables, donde la variable type es la variable a predecir.

Realice los siguientes pasos: 

1. Realice el proceso de pre-procesado. Divida el conjunto de datos en 70% para
el conjunto de entrenamiento y 30% para el conjunto de validación.

2. Realice un modelo de K vecinos más cercanos con la K óptima. Pruebe con 20
valores distintos de k y obtenga la evolución del Accuracy en función de la K,
seleccionando la k óptima. Utilice el modelo para predecir sobre el conjunto de
validación.

3. Realice un modelo de Super Vector Machine con distintos kernels (lineal,
polinómico y radial). Utilice el modelo para predecir sobre el conjunto de
validación

4. Obtenga el AUC del modelo de Knn y SVM ¿Cuál de los dos modelos podemos
considerar que es mejor en función del AUC? (para calcular el AUC deberá
transformar las predicciones a numéricas con la función ifelse()).

Interprete los resultados. Los datos se encuentran dentro de la librería kernlab
que debemos instalar (install.packages()) y cargar (library()). Para cargar los
datos se debe utilizar data(spam).

Descripción del conjunto de datos:

* Conjunto de datos recopilados en Hewlett-Packard Labs, que clasifica los
correos electrónicos 4601 como spam o no spam. Las primeras 57 variables nos
indican la frecuencia de ciertas palabras y caracteres en el correo electrónico
y la variable número 58 (type) clasifica el correo como spam o no.


## Paquetes

```{r}
options(warn = -1,
		  dplyr.summarise.inform = FALSE,
		  tibble.print_min = 5,
		  readr.show_col_types = FALSE)
```

```{r}
import::from(statistigo, coloring_font)
import::from(bestNormalize, bestNormalize)
import::from(statistigo, coloring_font)
import::from(skimr, skim)
import::from(parallel, detectCores, makePSOCKcluster, stopCluster)
import::from(doParallel, registerDoParallel)
import::from(cowplot, .except = "stamp")
import::from(kableExtra, .except = "group_rows")
import::from(DataExplorer, plot_intro, plot_bar, plot_density)
import::from(conectigo, cargar_fuentes)
import::from(rstatix, identify_outliers)
pacman::p_load(janitor, themis, usemodels, tidymodels, tidyverse)
```

## Funciones


```{r}
tabla <- function(df, cap = "prueba") {
  
  df %>% 
   kbl(booktabs = TRUE, caption = cap, escape = F) %>% 
   kable_paper(lightable_options = "hover", full_width = F)}
```

```{r}
resaltar <- function(texto) {
    
    glue::glue("<span style='background-color: #FFFF00'>**{texto}**</span>")
    
}
```

```{r}
# detener el backend
unregister <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}
```

<!-- #56B4E9 -->
<!-- #D55E00 -->

```{r}
barra <- function(df, x) {
	
	dfx <- df %>%
		tabyl({{x}}) %>% 
		adorn_pct_formatting()
	
	dfx %>% 
		ggplot(aes(y = {{x}}, x = n)) +
		geom_col(fill = "#0072B2", width = 0.8) +
		geom_text(aes(label = str_c(n, " ", "(", percent, ")")),
					 hjust = 1.5,
					 size = 6,
					 color = "white") +
					 # fontface = "bold") +
		scale_x_continuous(expand = c(0, 0)) +
		scale_y_discrete(name = NULL, expand = c(0, 0.5)) +
		coord_cartesian(clip = "off") +
		theme_minimal_vgrid(font_family = "yano") +
		theme(axis.text.y = element_text(size = 14),
				plot.title = element_text(size = 22, face = "bold"))
}
```

## Metricas

La fórmula del RMSLE es:

$$\sqrt{\frac{1}{n}\sum_{i = 1}^{n} (log(x_{i} + 1) - log(y_{i} + 1))^2}$$

Donde X es el valor predecido y Y es el valor actual

En el caso de RMSE, la presencia de valores atípicos puede hacer explotar el
término de error a un valor muy alto. Pero, en el caso de RMLSE, los valores
atípicos se reducen drásticamente, lo que anula su efecto.

Lo que sucede es que el RMSE se va a incrementar con la presencia de atípicos,
en cambio el **RMSLE no se afecta mucho**. El RMSLE es un error relativo.

Otro aspecto a considerar es que el RMSE aumenta si las medidas entre las
predicción y el valor actual son grandes. En cambio RMSLE es un valor relativo.

El factor más importante para utilizar el RMSLE es que RMSLE incurre en una
penalización mayor por la subestimación de la variable real que la
sobreestimación. En palabras simples, se incurre en más penalización cuando el
valor predicho es menor que el valor real. Por otro lado, se incurre en menos
penalización cuando el valor predicho es mayor que el valor real.

Esto es especialmente útil para casos en los que la subestimación de la variable
objetivo no es aceptable, pero se puede tolerar la sobreestimación.

Supongamos que sobrestimamos la renta de bicicletas, el adminstrador puede
tener más bicicletas disponibles para atender la demanda suponiendo que el costo
de mantener más bicicletas es menor que el costo de no rentarlas.  El problema
se daría si la cantidad de bicicletas predichas es menor, en este caso es
probable que el administrador pierda dinero por no tener suficientes bicicletas
para suplir la demanda.

```{r}
# métrica rmsle
rmsle_vec <- function(truth, estimate, na_rm = TRUE, ...) {
  
	rmsle_impl <- function(truth, estimate) {
    sqrt(mean((log(truth + 1) - log(estimate + 1))^2))
  }

  metric_vec_template(
    metric_impl = rmsle_impl,
    truth = truth,
    estimate = estimate,
    na_rm = na_rm,
    cls = "numeric",
    ...
  )
}

rmsle <- function(data, ...) {
  UseMethod("rmsle")
}
rmsle <- new_numeric_metric(rmsle, direction = "minimize")

rmsle.data.frame <- function(data, truth, estimate, na_rm = TRUE, ...) {
  metric_summarizer(
    metric_nm = "rmsle",
    metric_fn = rmsle_vec,
    data = data,
    truth = !!enquo(truth),
    estimate = !!enquo(estimate),
    na_rm = na_rm,
    ...
  )
}
```

## Opciones

```{r}
cargar_fuentes()
```

```{r}
yunkel <- theme_cowplot(font_family = "yano") +
	       theme(plot.margin = unit(c(3, 1, 1, 1), "mm"), 
	             axis.title = element_text(size = 12))
```

```{r}
# tema con grid horizontal y vertical
drako <- theme_bw(base_family = "yano", base_size = 14) +
	      theme(plot.margin = unit(c(6, 1, 1, 1), "mm"),
	            axis.title = element_text(size = 12),
	            plot.subtitle = element_text(size = 8,
                                            family = "sans"))
```

```{r}
theme_set(yunkel)
```

# Carga

Cargar los datos y transformar aquellas variables que se consideren factor.

```{r}
spam <- data("spam", package = "kernlab") %>%
	get() %>% as_tibble(.name_repair = make_clean_names)
```

<!-- https://bit.ly/31D95c4 -->

<!-- ~ 7% de error de clasificación errónea. Los falsos positivos (marcar un
buen --> <!-- correo como spam) son muy indeseables. Si insistimos en cero
falsos positivos en --> <!-- el conjunto de entrenamiento / prueba, el 20-25%
del spam pasó a través del --> <!-- filtro. -->

# Análisis Exploratorio

## Estructura

```{r}
head(spam)
```

```{r}
plot_intro(spam, ggtheme = yunkel)
```

Ninguna de nuestras variables tiene datos ausentes. Solo hay una variable
categórica.

```{r}
spam %>%
	skim() %>%
	as_tibble() %>%
	select(skim_variable, factor.top_counts:numeric.sd)
```

Vemos que la variable respuesta presenta un desbalance con 2788 casos para
`r coloring_font("**no_spam**", "#A24000")` y 1813 para
`r coloring_font("**spam**", "#A24000")`.

## Variables dependiente

(ref:desbalance) El desafío de trabajar con conjuntos de datos desequilibrados es que la mayoría de las técnicas de aprendizaje automático ignorarán y, a su vez, tendrán un rendimiento deficiente en la clase minoritaria, aunque normalmente lo más importante es el rendimiento en la clase minoritaria.

```{r, desbalance, fig.cap='(ref:desbalance)'}
spam %>% 
	barra(type) +
	labs(title = "Clasificación desequilibrada")
```

En el gráfico \@ref(fig:desbalance) observamos que la variable no está
equilibrada. La clase `r coloring_font("**no_spam**", "#A24000")` tiene más
casos que la clase `r coloring_font("**spam**", "#A24000")`. Si no balanceamos
los datos entonces lo que pasará es que nuestro modelo aprenderá de manera muy
eficaz sobre cómo predecir el caso negativo, es decir, cuando un correo no es
spam.

## Atípicos

```{r}
spam_longer <- spam %>% 
	pivot_longer(cols = where(is.numeric),
					 names_to = "variable",
					 values_to = "valor")
	# filter(variable %in% c("mail", "will", "all")) %>% 
	# mutate(variable = fct_reorder2(variable, type, valor, .fun = first2, .desc = F))
```




```{r}
spam_longer %>% 
	ggplot(aes(x = variable, y = valor)) +
	geom_boxplot(outlier.color = "red") +
	scale_y_log10() +
	facet_grid(type ~ ., scales = "free_y") +
	drako +
	theme(axis.text.x = element_text(angle = 90, hjust = 1))

```






# Split

```{r}
spam_split <- initial_split(data = spam, strata = type, prop = 0.7)
spam_train <- training(spam_split)
spam_test  <- testing(spam_split)
```

```{r}
dim(spam_train) # 70% para entrenamiento
```

## CV

Debido a que tenemos una muestra relativamente grande un CV con 10 K-fold será
suficiente para obtener buenas propiedades de bias y varianza.

```{r}
set.seed(2021)
spam_folds <- vfold_cv(spam_train, strata = type)
```

# Recetas

Crearemos varias recetas para poder probar con los distintos métodos que ayudan
a corregir el desequilibrio entre las distintas clases.

Lo que haremos en general será:

* Balancear los datos con distintos métodos.
* Remover variables que tengan cero varianza o varianza próxima a cero.
* Centrar y escalar

Antes de realizar este procedimiento, validemos cuantas variables quedarían
después de remover las variables tienen varianza cero o próxima a cero.

```{r}
recipe(formula = type ~ ., data = spam_train) %>% 
  step_nzv(all_predictors()) %>%
  prep() %>% 
  summary()
```

Vemos que solo quedan 9 predictores.

Ahora veamos que pasa si solo queremos retirar aquellas que tengan estrictamente
varianza cero:

```{r}
recipe(formula = type ~ ., data = spam_train) %>% 
  step_zv(all_predictors()) %>%
  prep() %>% 
  summary()
```

No hay ninguna variable que tenga varianza cero exacta.  Lo que haremos
será dejar una receta que contemple todos los predictores y seleccionaremos
un único método de balanceo, porque sino, tendríamos demasiadas recetas que
probar.

## SMOTE

**Synthetic Minority Oversampling TEchnique**

SMOTE funciona seleccionando ejemplos que están cerca en el espacio de
funciones, dibujando una línea entre los ejemplos en el espacio de funciones y
dibujando una nueva muestra en un punto a lo largo de esa línea.

SMOTE primero selecciona una instancia de clase minoritaria a al azar y
encuentra sus k vecinos de clase minoritaria más cercanos. Luego, la instancia
sintética se crea eligiendo uno de los k vecinos b más cercanos al azar y
conectando a y b para formar un segmento de línea en el espacio de
características. Las instancias sintéticas se generan como una combinación
convexa de las dos instancias elegidas a y b.

```{r}
knn_recipe_smote <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_nzv(all_predictors()) %>%
  step_normalize(all_numeric()) %>% 
  step_smote(type, skip = TRUE) 
```

Veamos como quedó esta receta a nivel de dataset:

```{r}
knn_recipe_smote %>%
	prep() %>%
	juice()
```

Vemos que, a como habíamos previsto, que la función `step_nzv()` excluyó 48
predictores debido a que tienen varianza próxima a cero, quedando únicamente
9 predictores más la respuesta.

(ref:smot) Realiza un sobremuestreo en el que la clase minoritaria se sobremuestrea creando ejemplos "sintéticos" en lugar de sobremuestrear con reemplazo.

```{r smot, fig.cap='(ref:smot)'}
knn_recipe_smote %>%
	prep() %>%
	juice() %>% 
	barra(type) + labs("Clasificación Balanceada")
```

## Submuestreo

Recordemos que en tidymodels las recetas de preprocesamiento que se apliquen
a los datos de entrenamiento luego se aplican a los datos de prueba.  En el caso
de pasos (*steps*) de pre-procesamiento que realizan sobre-muestreo o
sub-muestreo es muy importante que este paso **no se aplique a los datos que
estamos pronosticando**.  Por esta razón cuando usemos recetas debemos utilizar
una opción llamada  `skip = TRUE`  para que se  ignore este paso en la fase
de predicción (e.g con `predict()`).  

La idea principal es aislar los pasos de pre-procesamiento que podrían causar
errores si se aplican a nuevas muestras (e.g set de prueba).

```{r}
knn_recipe_submuestreo <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  step_downsample(type, skip = TRUE)
```

## Sobremuestreo

```{r}
knn_recipe_sobremuestreo <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  step_upsample(type, skip = TRUE)
```

## ROSE

```{r}
knn_recipe_rose <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  step_rose(type, skip = TRUE)
```

# Modelado

```{r}
knn_spec <- nearest_neighbor(neighbors = tune(),   # este es la cantidad de vecinos k a estimar
									  weight_func = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn")
```

```{r}
preprocesadores_knn <- list(knn_smote = knn_recipe_smote, 
									 knn_submu = knn_recipe_submuestreo,
									 knn_sobre = knn_recipe_sobremuestreo,
									 knn_rosex = knn_recipe_rose)
```


```{r}
modelo_knn <- list(knn = knn_spec)
```


```{r}
spam_workflow <- workflow_set(preprocesadores_knn, modelo_knn)
```

Con la función `control_grid()` lo que haremos será retener los modelos y
recetas ajustados. Además, cuando establecemos la opción save_pred en TRUE
conservaremos las predicciones del conjunto de evaluación y podremos acceder a
ellas mediante `collect_predictions()` .

```{r}
grid_ctrl <- control_grid(
      save_pred = TRUE,
      parallel_over = "everything",
      save_workflow = TRUE)
```

Ahora aplicaremos la función `workflow_map` para aplicar cada modelo a su receta
correspondiente dentro de cada pliego (fold).


```{r}
# Crear un cluster con sesiones de R para agregar paralelismo
all_cores <- detectCores(logical = FALSE)
cl <- makePSOCKcluster(all_cores)
registerDoParallel(cl)
set.seed(2021)
```



```{r}
set.seed(84432)
knn_tune <- tune_grid(knn_workflow,
  							 resamples = spam_folds,
							 control = grid_ctrl,
							 grid = 20)
```



# Referencias





























