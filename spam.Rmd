---
title: KNN - SVM
subtitle: Ejercicio Obligatorio
author:
- name: William Chavarría
  affiliation: Máxima Formación
  email: wchavarria@tigo.com.gt
date: '`r format(Sys.Date())`'
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
    highlight: pygments
    theme: spacelab
    css: custom_knn.css
    fig_caption: true
    df_print: paged
bibliography: [paquetes_knn.bib, knn.bib]
biblio-style: "apalike"
link-citations: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo        = TRUE, 
                      include     = TRUE,
                      cache       = FALSE,
                      fig.align   = 'center',
                      message     = FALSE,
                      warning     = FALSE, 
                      comment     = NA, 
                      highlight   = TRUE,
                      strip.white = TRUE,
                      dev         = "svglite",
                      fig.width   = 8,
                      fig.asp     = 0.618,
                      fig.show    = "hold",
                      fig.align   = "center")
```

# spam {.tabset .tabset-fade .tabset-pills}

## Descripción

Datos spam. Se desea realizar un modelo para clasificar si un correo se puede
considerar spam o no. Se nos proporciona un conjunto de datos con 4.601
observaciones y 58 variables, donde la variable type es la variable a predecir.

Realice los siguientes pasos: 

1. Realice el proceso de pre-procesado. Divida el conjunto de datos en 70% para
el conjunto de entrenamiento y 30% para el conjunto de validación.

2. Realice un modelo de K vecinos más cercanos con la K óptima. Pruebe con 20
valores distintos de k y obtenga la evolución del Accuracy en función de la K,
seleccionando la k óptima. Utilice el modelo para predecir sobre el conjunto de
validación.

3. Realice un modelo de Super Vector Machine con distintos kernels (lineal,
polinómico y radial). Utilice el modelo para predecir sobre el conjunto de
validación

4. Obtenga el AUC del modelo de Knn y SVM ¿Cuál de los dos modelos podemos
considerar que es mejor en función del AUC? (para calcular el AUC deberá
transformar las predicciones a numéricas con la función ifelse()).

Interprete los resultados. Los datos se encuentran dentro de la librería kernlab
que debemos instalar (install.packages()) y cargar (library()). Para cargar los
datos se debe utilizar data(spam).

Descripción del conjunto de datos:

* Conjunto de datos recopilados en Hewlett-Packard Labs, que clasifica los
correos electrónicos 4601 como spam o no spam. Las primeras 57 variables nos
indican la frecuencia de ciertas palabras y caracteres en el correo electrónico
y la variable número 58 (type) clasifica el correo como spam o no.


## Paquetes

```{r}
options(warn = -1,
		  dplyr.summarise.inform = FALSE,
		  tibble.print_min = 5,
		  readr.show_col_types = FALSE)
```

```{r}
import::from(statistigo, coloring_font)
import::from(bestNormalize, bestNormalize)
import::from(statistigo, coloring_font)
import::from(skimr, skim)
import::from(parallel, detectCores, makePSOCKcluster, stopCluster)
import::from(doParallel, registerDoParallel)
import::from(cowplot, .except = "stamp")
import::from(kableExtra, .except = "group_rows")
import::from(DataExplorer, plot_intro, plot_bar, plot_density)
import::from(conectigo, cargar_fuentes)
pacman::p_load(janitor, themis, usemodels, tidymodels, tidyverse)
```

## Funciones

```{r}
# agregar línea loess a las gráficas ggpairs
loess_lm <- function(data, mapping, ...){
 
ggplot(data = data, mapping = mapping) + 
    geom_point(alpha = 0.9) + 
    stat_smooth(formula = y ~ x, 
                method = "lm", 
                se = TRUE, 
                color = "blue",
                fill = "blue",
                size = 0.5, 
                alpha = 0.2,
                linetype = "longdash", 
                ...)
}
```

```{r}
tabla <- function(df, cap = "prueba") {
  
  df %>% 
   kbl(booktabs = TRUE, caption = cap, escape = F) %>% 
   kable_paper(lightable_options = "hover", full_width = F)}
```

```{r}
formatear_df <- function(df, pval) {
	
	pv <- df[[pval]]
	
	df %>% 
		mutate(
			across(where(is.numeric), round, 4),
			across(.data[[pval]], rd, 2),
			sig = starmaker(x = pv, p.levels = c(.001, .01, .05, .1), 
								 symbols = c("***", "**", "\\*", "\\+")))
}
```

```{r}
# generar gráfico de densidad
estimar_densidad <- function(df, d, color) {
	
	brk <- hist(df[[d]], plot = FALSE)$breaks 
	med <- mean(df[[d]])
	
	df %>% 
	  ggplot(aes(x = .data[[d]], y = ..density..)) +
	  geom_histogram(fill   = color,
	                 colour = "black",
	                 size   = .2,
	                 breaks = brk) +
	  scale_x_continuous(name   = d,
	                     breaks = brk) +
	  geom_density(size = 1) +
	  geom_vline(xintercept = med, 
	             linetype = "dashed",
	             color = "red", 
	             alpha = 0.5) 
}
```

```{r}
# crear qq-plots
qpl <- function(df, var_y, rel) { 
      
      df %>% 
       ggplot(aes(sample = .data[[var_y]])) +
       qq$geom_qq_band(bandType = "pointwise", 
                       distribution = "norm", 
                       alpha = 0.5) +
       qq$stat_qq_line() +
       qq$stat_qq_point(size   = 2, 
                        shape  = 21, 
                        alpha  = 0.8, 
                        fill   = rel, 
                        colour = rel) +
       labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +
       ggtitle(str_to_title(var_y)) +
       theme(plot.title = element_text(size = 16))
      
     }
```


```{r}
# pruebas de normalidad no paramétrica
funciones <- list(
 
  shapiro_wilk       = function(x) shapiro.test(x),
  jarque_bera        = function(x) JarqueBeraTest(x, robust = F),
  pearson            = function(x) pearson.test(x), 
  shapiro_francia    = function(x) sf.test(x),
  kolgomoro_smirnov  = function(x) lillie.test(x)
)
```

```{r}
# aplicar pruebas de normalidad
probar_normalidad <- function(vector) {
	
	funciones %>% 
		map(exec, x = vector) %>% 
		map_df(tidy) %>% 
		select(method, p_value = p.value) %>% 
		# mutate(normalidad = ifelse(p_value < 0.05, "NO_NORMAL", "NORMAL")) %>% 
		arrange(desc(p_value))
}
```

```{r}
resaltar <- function(texto) {
    
    glue::glue("<span style='background-color: #FFFF00'>**{texto}**</span>")
    
}
```

```{r}
# detener el backend
unregister <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}
```

## Metricas

La fórmula del RMSLE es:

$$\sqrt{\frac{1}{n}\sum_{i = 1}^{n} (log(x_{i} + 1) - log(y_{i} + 1))^2}$$

Donde X es el valor predecido y Y es el valor actual

En el caso de RMSE, la presencia de valores atípicos puede hacer explotar el
término de error a un valor muy alto. Pero, en el caso de RMLSE, los valores
atípicos se reducen drásticamente, lo que anula su efecto.

Lo que sucede es que el RMSE se va a incrementar con la presencia de atípicos,
en cambio el **RMSLE no se afecta mucho**. El RMSLE es un error relativo.

Otro aspecto a considerar es que el RMSE aumenta si las medidas entre las
predicción y el valor actual son grandes. En cambio RMSLE es un valor relativo.

El factor más importante para utilizar el RMSLE es que RMSLE incurre en una
penalización mayor por la subestimación de la variable real que la
sobreestimación. En palabras simples, se incurre en más penalización cuando el
valor predicho es menor que el valor real. Por otro lado, se incurre en menos
penalización cuando el valor predicho es mayor que el valor real.

Esto es especialmente útil para casos en los que la subestimación de la variable
objetivo no es aceptable, pero se puede tolerar la sobreestimación.

Supongamos que sobrestimamos la renta de bicicletas, el adminstrador puede
tener más bicicletas disponibles para atender la demanda suponiendo que el costo
de mantener más bicicletas es menor que el costo de no rentarlas.  El problema
se daría si la cantidad de bicicletas predichas es menor, en este caso es
probable que el administrador pierda dinero por no tener suficientes bicicletas
para suplir la demanda.

```{r}
# métrica rmsle
rmsle_vec <- function(truth, estimate, na_rm = TRUE, ...) {
  
	rmsle_impl <- function(truth, estimate) {
    sqrt(mean((log(truth + 1) - log(estimate + 1))^2))
  }

  metric_vec_template(
    metric_impl = rmsle_impl,
    truth = truth,
    estimate = estimate,
    na_rm = na_rm,
    cls = "numeric",
    ...
  )
}

rmsle <- function(data, ...) {
  UseMethod("rmsle")
}
rmsle <- new_numeric_metric(rmsle, direction = "minimize")

rmsle.data.frame <- function(data, truth, estimate, na_rm = TRUE, ...) {
  metric_summarizer(
    metric_nm = "rmsle",
    metric_fn = rmsle_vec,
    data = data,
    truth = !!enquo(truth),
    estimate = !!enquo(estimate),
    na_rm = na_rm,
    ...
  )
}
```

## Opciones

```{r}
cargar_fuentes()
```

```{r}
yunkel <- theme_cowplot(font_family = "yano") +
	       theme(plot.margin = unit(c(3, 1, 1, 1), "mm"), 
	             axis.title = element_text(size = 12))
```

```{r}
# tema con grid horizontal y vertical
drako <- theme_bw(base_family = "yano", base_size = 14) +
	      theme(plot.margin = unit(c(6, 1, 1, 1), "mm"),
	            axis.title = element_text(size = 12),
	            plot.subtitle = element_text(size = 8,
                                            family = "sans"))
```

```{r}
theme_set(yunkel)
```

# Carga

Cargar los datos y transformar aquellas variables que se consideren factor.

```{r}
spam <- data("spam", package = "kernlab") %>%
	get() %>% as_tibble(.name_repair = make_clean_names)
```

<!-- https://bit.ly/31D95c4 -->

<!-- ~ 7% de error de clasificación errónea. Los falsos positivos (marcar un
buen --> <!-- correo como spam) son muy indeseables. Si insistimos en cero
falsos positivos en --> <!-- el conjunto de entrenamiento / prueba, el 20-25%
del spam pasó a través del --> <!-- filtro. -->

# Análisis Exploratorio

## Estructura

```{r}
head(spam)
```

```{r}
plot_intro(spam, ggtheme = yunkel)
```

Ninguna de nuestras variables tiene datos ausentes. Solo hay una variable
categórica.

```{r}
spam %>%
	skim() %>%
	as_tibble() %>%
	select(skim_variable, factor.top_counts:numeric.sd)
```

Vemos que la variable respuesta presenta un desbalance con 2788 casos para
`r coloring_font("**no_spam**", "#A24000")` y 1813 para
`r coloring_font("**spam**", "#A24000")`.

## Variables dependiente

```{r}
spam %>% 
	ggplot(aes(x = type)) +
	geom_bar() +
	labs(title = "Frecuencia de la variable Type")
```

En el gráfico observamos que la variable no está equilibrada. La clase
`r coloring_font("**no_spam**", "#A24000")` tiene más casos que la clase
`r coloring_font("**spam**", "#A24000")`

# Split

```{r}
spam_split <- initial_split(data = spam, strata = type, prop = 0.7)
spam_train <- training(spam_split)
spam_test  <- testing(spam_split)
```

```{r}
dim(spam_train) # 70% para entrenamiento
```

```{r, paged.print = FALSE}
spam_train %>% 
	tabyl(type) %>% 
	adorn_pct_formatting() %>% 
	adorn_totals(where = "row", name = "total") %>% 
	tabla("Cantidad de Spam en train")
```

# Balanceo

Si no balanceamos los datos entonces lo que pasará es que nuestro modelo
aprenderá de manera muy eficaz sobre cómo predecir el caso negativo, es decir,
cuando un correo no es spam.

En lugar de utilizar `step_rose`, el cual es un *wrapper* de la función
`ovun.sample` del paquete {ROSE}, utilizaremos `step_upsample()`. Lo que hará
esta función será hacer que todos los demás niveles se muestrean para que tengan
la misma frecuencia que el nivel más frecuente. 

```{r}
recipe(type ~ ., spam_train) %>% 
	step_upsample(type, over_ratio = 1) %>% 
	# step_rose(type) %>% 
	prep() %>% 
	juice() %>%
	ggplot(aes(y = type)) +
	geom_bar(fill = "#56B4E9", width = 0.8, alpha = 0.8) +
	scale_x_continuous(expand = c(0, 0)) +
	scale_y_discrete(name = NULL, expand = c(0, 0.5)) +
	coord_cartesian(clip = "off") +
	theme_minimal_vgrid(font_family = "yano") +
	labs(title = "Sobremuestreo")
```

# Entrenar

Debido a que tenemos una muestra relativamente grande un CV con 10 K-fold será
suficiente para obtener buenas propiedades de bias y varianza.

```{r}
set.seed(2021)
spam_folds <- vfold_cv(spam_train, strata = type)
```

Crearemos varias recetas para poder probar con los distintos métodos que ayudan
a corregir el desequilibrio entre las distintas clases.

Lo que haremos en general será:

* Balancear los datos con distintos métodos.
* Remover variables que tengan cero varianza o varianza próxima a cero.
* Centrar y escalar

```{r}
(kknn_recipe_submuestreo <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_downsample(type, under_ratio = 1) %>% 
  prep() %>% juice() %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  prep())
```


```{r}
(kknn_recipe_sobremuestreo <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_upsample(type, over_ratio = 1) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  prep())
```

```{r}
(kknn_recipe_rose <- recipe(formula = type ~ ., data = spam_train) %>% 
  step_rose(type, skip = TRUE) %>% 
  step_nzv(all_predictors()) %>% 
  step_normalize(all_numeric()) %>% 
  prep())
```




```{r}
kknn_spec <- 
  nearest_neighbor(neighbors = tune(), weight_func = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("kknn")
```


```{r}
kknn_workflow <- 
  workflow() %>% 
  add_recipe(kknn_recipe) %>% 
  add_model(kknn_spec)
```


```{r}
set.seed(84432)
kknn_tune <- tune_grid(kknn_workflow,
  							  resamples = spam_folds,
							  grid = 20)
```



# Referencias





























